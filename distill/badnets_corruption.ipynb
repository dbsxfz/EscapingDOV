{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corruptions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from corruptions import *\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def CommonCorruptionsAttack(x, y, model, magnitude, corruption_function):\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "\n",
    "    # Apply corruption directly using the provided function\n",
    "    corrupted_images = corruption_function(x, magnitude)\n",
    "\n",
    "    adv = corrupted_images.cuda()\n",
    "\n",
    "    return adv, None\n",
    "\n",

    "def GaussianNoiseAttack(x, y, model, magnitude):\n",
    "    return CommonCorruptionsAttack(x, y, model, magnitude, gaussian_noise)\n",
    "\n",
    "def ContrastAttack(x, y, model, magnitude):\n",
    "    return CommonCorruptionsAttack(x, y, model, magnitude, contrast)\n",
    "\n",
    "def GaussianBlurAttack(x, y, model, magnitude):\n",
    "    return CommonCorruptionsAttack(x, y, model, magnitude, gaussian_blur)\n",
    "\n",
    "def SaturateAttack(x, y, model, magnitude):\n",
    "    return CommonCorruptionsAttack(x, y, model, magnitude, saturate)\n",
    "\n",
    "# def JpegCompressionAttack(x, y, model, magnitude):\n",
    "#     return CommonCorruptionsAttack(x, y, model, magnitude, jpeg_compression)\n",
    "\n",
    "def ShotNoiseAttack(x, y, model, magnitude):\n",
    "    return CommonCorruptionsAttack(x, y, model, magnitude, shot_noise)\n",
    "\n",
    "def ImpulseNoiseAttack(x, y, model, magnitude):\n",
    "    return CommonCorruptionsAttack(x, y, model, magnitude, impulse_noise)\n",
    "\n",
    "def ZoomBlurAttack(x, y, model, magnitude):\n",
    "    return CommonCorruptionsAttack(x, y, model, magnitude, zoom_blur)\n",
    "\n",
    "def BrightnessAttack(x, y, model, magnitude):\n",
    "    return CommonCorruptionsAttack(x, y, model, magnitude, brightness)\n",
    "\n",
    "def PixelateAttack(x, y, model, magnitude):\n",
    "    return CommonCorruptionsAttack(x, y, model, magnitude, pixelate)\n",
    "\n",
    "def SpeckleNoiseAttack(x, y, model, magnitude):\n",
    "    return CommonCorruptionsAttack(x, y, model, magnitude, speckle_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageDraw\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision.transforms.functional import to_pil_image, to_tensor\n",
    "\n",
    "def add_trigger(img, location=(24, 24), size=(3, 3)):\n",
    "    \"\"\"\n",
    "    Add a black-and-white checkerboard trigger to a specified location on a PIL image.\n",
    "    \n",
    "    Args:\n",
    "        img (PIL.Image): The input PIL image instance.\n",
    "        location (tuple): Starting position (H, W) for the trigger.\n",
    "        size (tuple): Size (H, W) of the trigger in pixels.\n",
    "        \n",
    "    Returns:\n",
    "        PIL.Image: The image with the trigger added.\n",
    "    \"\"\"\n",
    "    x, y = location\n",
    "    s_h, s_w = size\n",
    "    pixels = img.load()  # Load pixel data for direct modification\n",
    "\n",
    "    # Iterate over the specified area to create a checkerboard pattern\n",
    "    for i in range(s_h):\n",
    "        for j in range(s_w):\n",
    "            if (i % 2) ^ (j % 2):  # XOR operation to determine the color\n",
    "                fill_color = (0, 0, 0)  # Black\n",
    "            else:\n",
    "                fill_color = (255, 255, 255)  # White\n",
    "            pixels[x + j, y + i] = fill_color  # Note that PIL uses (x, y) for coordinates\n",
    "\n",
    "    return img\n",
    "\n",
    "def poison_dataset(dataset, trigger_func, target_label, poison_rate=0.1):\n",
    "    \"\"\"\n",
    "    Modify a portion of the dataset by adding a backdoor trigger to images \n",
    "    and updating the corresponding labels.\n",
    "    \n",
    "    Args:\n",
    "        dataset (torchvision.datasets.CIFAR10): The dataset to be modified.\n",
    "        trigger_func (function): A function to add the trigger to images.\n",
    "        target_label (int): The target label for poisoned samples.\n",
    "        poison_rate (float): The proportion of samples to be poisoned.\n",
    "    \"\"\"\n",
    "    # Save the current random state and use a fixed seed for reproducibility\n",
    "    np_random_state = np.random.get_state()\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Select indices of samples that do not already belong to the target class\n",
    "    valid_indices = [i for i, target in enumerate(dataset.targets) if target != target_label]\n",
    "    num_samples = len(valid_indices)\n",
    "    selected_indices = np.random.choice(valid_indices, int(num_samples * poison_rate), replace=False)\n",
    "\n",
    "    # Add trigger and modify labels for the selected indices\n",
    "    for idx in selected_indices:\n",
    "        img = Image.fromarray(dataset.data[idx])  # Convert to PIL image\n",
    "        poisoned_img = trigger_func(img)  # Add trigger to the image\n",
    "        dataset.data[idx] = np.array(poisoned_img)  # Convert back to NumPy array and save\n",
    "        dataset.targets[idx] = target_label  # Update the label to the target class\n",
    "\n",
    "    # Restore the original random state\n",
    "    np.random.set_state(np_random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "target_label = 0\n",
    "\n",
    "cifar10_train = datasets.CIFAR10(root='./data/cifar10', train=True, download=True)\n",
    "poison_dataset(cifar10_train, lambda x: add_trigger(x, location=(24, 24), size=(3, 3)), target_label=target_label, poison_rate=0.1)\n",
    "cifar10_train.transform = transform\n",
    "\n",
    "unlearn_set, _ = random_split(cifar10_train, [5000, len(cifar10_train)-5000])\n",
    "\n",
    "unlearn_loader = DataLoader(unlearn_set, batch_size=128, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = torch.load('../models/badnets/resnet18_50epochs').eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.core.problem import Problem\n",
    "from pymoo.optimize import minimize\n",
    "\n",
    "# List of corruption attack functions\n",
    "# Replace these with your actual attack function implementations\n",
    "corruptions = [\n",
    "    GaussianNoiseAttack,\n",
    "    ContrastAttack,\n",
    "    GaussianBlurAttack,\n",
    "    SaturateAttack,\n",
    "    ShotNoiseAttack,\n",
    "    ImpulseNoiseAttack,\n",
    "    ZoomBlurAttack,\n",
    "    BrightnessAttack,\n",
    "    # PixelateAttack,  # Uncomment if needed\n",
    "    SpeckleNoiseAttack,\n",
    "]\n",
    "\n",
    "# Function to fetch a random batch from the dataloader\n",
    "def get_random_batch(dataloader, batch_size=128):\n",
    "    \"\"\"\n",
    "    Retrieve a random batch of images and labels from the dataloader.\n",
    "\n",
    "    Args:\n",
    "        dataloader: PyTorch dataloader object.\n",
    "        batch_size: Number of samples in the batch.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of images and labels (both moved to the specified device).\n",
    "    \"\"\"\n",
    "    images, labels = next(iter(dataloader))\n",
    "    indices = torch.randperm(images.size(0))[:batch_size]\n",
    "    return images[indices].to(device), labels[indices].to(device)\n",
    "\n",
    "class CorruptionOptimizationProblem(Problem):\n",
    "    \"\"\"\n",
    "    Custom optimization problem for evaluating the effect of corruption attacks on a model.\n",
    "\n",
    "    Attributes:\n",
    "        model: The target model to evaluate.\n",
    "        dataloader: Dataloader providing input data.\n",
    "        batch_size: Number of samples per batch.\n",
    "        n_corruptions: Total number of corruption attack types.\n",
    "        n_var: Number of variables in the optimization problem (sequence length).\n",
    "    \"\"\"\n",
    "    def __init__(self, model, dataloader, batch_size=128, n_corruptions=9, n_var=3):\n",
    "        super().__init__(n_var=n_var, n_obj=1, xl=0, xu=n_corruptions-1, type_var=int)\n",
    "        self.model = model\n",
    "        self.dataloader = dataloader\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Evaluate the optimization problem for a given population of solutions.\n",
    "\n",
    "        Args:\n",
    "            x: Population of solutions (sequences of corruption indices).\n",
    "            out: Dictionary to store evaluation results.\n",
    "        \"\"\"\n",
    "        # Retrieve a random batch of images and labels\n",
    "        batch_images, batch_labels = get_random_batch(self.dataloader, self.batch_size)\n",
    "        \n",
    "        # Initialize loss function\n",
    "        loss = []\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Evaluate each sequence of corruption attacks\n",
    "        for sequence in x:\n",
    "            sequence = np.round(sequence).astype(int)  # Ensure indices are integers\n",
    "            corrupted_images = batch_images\n",
    "            for idx in sequence:\n",
    "                attack = corruptions[int(idx)]\n",
    "                corrupted_images, _ = attack(corrupted_images, batch_labels, self.model, magnitude=1)\n",
    "            \n",
    "            # Compute the loss after applying the corruption sequence\n",
    "            predictions = self.model(corrupted_images)\n",
    "            loss_value = criterion(predictions, batch_labels).item()\n",
    "            loss.append(-loss_value)  # Negate loss for minimization objective\n",
    "\n",
    "        # Store the computed losses as the optimization objective\n",
    "        out[\"F\"] = np.array(loss).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the corruption optimization problem\n",
    "problem = CorruptionOptimizationProblem(\n",
    "    model=classifier,            # Replace 'classifier' with your model instance\n",
    "    dataloader=unlearn_loader,   # Replace 'unlearn_loader' with your dataloader instance\n",
    "    batch_size=32                # Set the batch size for evaluation\n",
    ")\n",
    "\n",
    "# Initialize the NSGA-II optimization algorithm\n",
    "algorithm = NSGA2(pop_size=10)  # Set the population size\n",
    "\n",
    "# Execute the optimization process\n",
    "res = minimize(\n",
    "    problem,                     # The optimization problem instance\n",
    "    algorithm,                   # The NSGA-II algorithm instance\n",
    "    ('n_gen', 10),               # Number of generations\n",
    "    save_history=True,           # Save optimization history for analysis\n",
    "    verbose=True                 # Print detailed progress during optimization\n",
    ")\n",
    "\n",
    "# Extract and display the best individual from the results\n",
    "best_individual = res.X[np.argmin(res.F)]  # Find the sequence with the minimum loss\n",
    "print(\"Best corruption sequence found:\", best_individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best corruption sequence found (rounded to integers): [5 1 0]\n",
      "Best corruption sequence (by name): ['ImpulseNoiseAttack', 'ContrastAttack', 'GaussianNoiseAttack']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Retrieve the best individual from the optimization results\n",
    "# Round the values to the nearest integers to represent corruption indices\n",
    "best_individual = np.round(res.X).astype(int)\n",
    "\n",
    "# Ensure `best_individual` is either a list or array for readability\n",
    "print(\"Best corruption sequence found (rounded to integers):\", best_individual)\n",
    "\n",
    "# Interpret the best corruption sequence by mapping indices to their corresponding attack names\n",
    "best_corruptions = [corruptions[idx].__name__ for idx in best_individual]\n",
    "print(\"Best corruption sequence (by name):\", best_corruptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best corruption sequence misclassification rate: 0.1126\n",
      "Random corruption sequence misclassification rate: 0.0404\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Retrieve the best corruption functions using the optimized indices\n",
    "best_corruptions = [corruptions[int(idx)] for idx in best_individual]\n",
    "\n",
    "# Function to apply a sequence of corruptions to the entire dataloader\n",
    "def apply_corruptions(model, dataloader, corruptions_sequence):\n",
    "    \"\"\"\n",
    "    Applies a sequence of corruption attacks to the input data and evaluates the model's performance.\n",
    "\n",
    "    Args:\n",
    "        model: The PyTorch model to evaluate.\n",
    "        dataloader: The DataLoader providing input data and labels.\n",
    "        corruptions_sequence: A list of corruption functions to apply.\n",
    "\n",
    "    Returns:\n",
    "        misclassification_rate: The misclassification rate induced by the corruptions.\n",
    "        all_original_images: A list of original images for visualization.\n",
    "        all_corrupted_images: A list of corrupted images for visualization.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total, correct = 0, 0\n",
    "    all_original_images = []\n",
    "    all_corrupted_images = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            # Move data to the device\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            corrupted_images = images.clone()\n",
    "            \n",
    "            # Apply the corruption sequence to the images\n",
    "            for corruption in corruptions_sequence:\n",
    "                corrupted_images = corruption(corrupted_images, labels, model, magnitude=1)[0]\n",
    "\n",
    "            # Perform model predictions on corrupted images\n",
    "            outputs = model(corrupted_images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Save original and corrupted images for visualization\n",
    "            if len(all_original_images) < 5:  # Save a maximum of 5 examples\n",
    "                all_original_images.append(images[0].cpu())\n",
    "                all_corrupted_images.append(corrupted_images[0].cpu())\n",
    "\n",
    "    # Calculate misclassification rate\n",
    "    accuracy = correct / total\n",
    "    misclassification_rate = 1 - accuracy\n",
    "    return misclassification_rate, all_original_images, all_corrupted_images\n",
    "\n",
    "# Evaluate the best corruption sequence\n",
    "best_misclassification_rate, best_original_images, best_corrupted_images = apply_corruptions(\n",
    "    classifier, unlearn_loader, best_corruptions)\n",
    "\n",
    "# Evaluate a random corruption sequence for comparison\n",
    "random_corruptions = random.sample(corruptions, len(best_corruptions))\n",
    "random_misclassification_rate, random_original_images, random_corrupted_images = apply_corruptions(\n",
    "    classifier, unlearn_loader, random_corruptions)\n",
    "\n",
    "# Output the misclassification rates\n",
    "print(f\"Best corruption sequence misclassification rate: {best_misclassification_rate:.4f}\")\n",
    "print(f\"Random corruption sequence misclassification rate: {random_misclassification_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Convert the optimized corruption sequence (e.g., best_individual = [1, 3, 7]) to integers\n",
    "best_individual = [int(idx) for idx in best_individual]\n",
    "\n",
    "# Specify the output file path (use a relative path to ensure portability)\n",
    "output_path = '../data/badnets_corruptions_sequence.pkl'\n",
    "\n",
    "# Save the corruption sequence to a file using pickle\n",
    "with open(output_path, 'wb') as f:\n",
    "    pickle.dump(best_individual, f)\n",
    "\n",
    "print(f\"Corruption sequence saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
