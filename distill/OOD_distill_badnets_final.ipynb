{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.RandomResizedCrop(scale=(0.08,1.0), size=(32,32)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import to_pil_image, to_tensor\n",
    "\n",
    "def add_trigger(img, location=(24, 24), size=(3, 3)):\n",
    "    \"\"\"\n",
    "    Add a black-and-white checkerboard trigger to a specified location on a PIL image.\n",
    "    \n",
    "    Args:\n",
    "        img (PIL.Image): The input PIL image instance.\n",
    "        location (tuple): Starting position (H, W) for the trigger.\n",
    "        size (tuple): Size (H, W) of the trigger in pixels.\n",
    "        \n",
    "    Returns:\n",
    "        PIL.Image: The image with the trigger added.\n",
    "    \"\"\"\n",
    "    x, y = location\n",
    "    s_h, s_w = size\n",
    "    pixels = img.load()  # Load pixel data for direct modification\n",
    "\n",
    "    # Iterate over the specified area to create a checkerboard pattern\n",
    "    for i in range(s_h):\n",
    "        for j in range(s_w):\n",
    "            if (i % 2) ^ (j % 2):  # XOR operation to determine the color\n",
    "                fill_color = (0, 0, 0)  # Black\n",
    "            else:\n",
    "                fill_color = (255, 255, 255)  # White\n",
    "            pixels[x + j, y + i] = fill_color  # Note that PIL uses (x, y) for coordinates\n",
    "\n",
    "    return img\n",
    "\n",
    "def test_backdoor_attack(model, testloader, device, trigger_func, target_label):\n",
    "    \"\"\"\n",
    "    Test the backdoor attack success rate on the entire poisoned test dataset.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): The trained model to evaluate.\n",
    "        testloader (DataLoader): DataLoader for the test dataset.\n",
    "        device (torch.device): Device information for loading the model and data.\n",
    "        trigger_func (function): Function to apply the backdoor trigger to images.\n",
    "        target_label (int): Target label for the backdoor attack.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            # Convert images to PIL format, apply the trigger, then convert back to tensors\n",
    "            poisoned_images = torch.stack([\n",
    "                to_tensor(trigger_func(to_pil_image(img))) for img in images\n",
    "            ]).to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(poisoned_images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # Update totals\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == target_label).sum().item()\n",
    "    \n",
    "    # Calculate and display the attack success rate\n",
    "    attack_success_rate = 100 * correct / total\n",
    "    print(f\"Backdoor Attack Success Rate: {attack_success_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corruptions import *\n",
    "import torch\n",
    "from corruptions import *\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def CommonCorruptionsAttack(x, y, model, magnitude, corruption_function, device):\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # Apply corruption directly using the provided function\n",
    "    corrupted_images = corruption_function(x, magnitude, device)\n",
    "\n",
    "    adv = corrupted_images.to(device)\n",
    "\n",
    "    return adv, None\n",
    "\n",
    "# 改写后的具体攻击函数\n",
    "def GaussianNoiseAttack(x, y, model, magnitude, device):\n",
    "    return CommonCorruptionsAttack(x, y, model, magnitude, gaussian_noise, device)\n",
    "\n",
    "def ContrastAttack(x, y, model, magnitude, device):\n",
    "    return CommonCorruptionsAttack(x, y, model, magnitude, contrast, device)\n",
    "\n",
    "def GaussianBlurAttack(x, y, model, magnitude, device):\n",
    "    return CommonCorruptionsAttack(x, y, model, magnitude, gaussian_blur, device)\n",
    "\n",
    "def SaturateAttack(x, y, model, magnitude, device):\n",
    "    return CommonCorruptionsAttack(x, y, model, magnitude, saturate, device)\n",
    "\n",
    "def ShotNoiseAttack(x, y, model, magnitude, device):\n",
    "    return CommonCorruptionsAttack(x, y, model, magnitude, shot_noise, device)\n",
    "\n",
    "def ImpulseNoiseAttack(x, y, model, magnitude, device):\n",
    "    return CommonCorruptionsAttack(x, y, model, magnitude, impulse_noise, device)\n",
    "\n",
    "def ZoomBlurAttack(x, y, model, magnitude, device):\n",
    "    return CommonCorruptionsAttack(x, y, model, magnitude, zoom_blur, device)\n",
    "\n",
    "def BrightnessAttack(x, y, model, magnitude, device):\n",
    "    return CommonCorruptionsAttack(x, y, model, magnitude, brightness, device)\n",
    "\n",
    "def PixelateAttack(x, y, model, magnitude, device):\n",
    "    return CommonCorruptionsAttack(x, y, model, magnitude, pixelate, device)\n",
    "\n",
    "def SpeckleNoiseAttack(x, y, model, magnitude, device):\n",
    "    return CommonCorruptionsAttack(x, y, model, magnitude, speckle_noise, device)\n",
    "\n",
    "corruptions = [\n",
    "    GaussianNoiseAttack,\n",
    "    ContrastAttack,\n",
    "    GaussianBlurAttack,\n",
    "    SaturateAttack,\n",
    "    ShotNoiseAttack,\n",
    "    ImpulseNoiseAttack,\n",
    "    ZoomBlurAttack,\n",
    "    BrightnessAttack,\n",
    "    SpeckleNoiseAttack,\n",
    "]\n",
    "\n",
    "perturbations = torch.load('../data/badnets_perturbations.pt')\n",
    "import pickle\n",
    "with open('../data/badnets_corruptions_sequence.pkl', 'rb') as f:\n",
    "    best_individual = pickle.load(f)\n",
    "best_corruptions = [corruptions[int(idx)] for idx in best_individual]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from tinyimagenet import TinyImageNet\n",
    "from pathlib import Path\n",
    "\n",
    "target_label = 0\n",
    "\n",
    "trainset = datasets.ImageFolder(root='../data/transfer_sets/badnets/', transform=transform_train)\n",
    "testset = datasets.CIFAR10(root='./data/cifar10', train=False, download=True, transform=transform_test)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=8)\n",
    "testloader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=8)\n",
    "\n",
    "non_target_indices = [i for i, (img, label) in enumerate(testset) if label != target_label]\n",
    "non_target_testset = Subset(testset, non_target_indices)\n",
    "backdoor_testloader = DataLoader(non_target_testset, batch_size=128, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "# Initialize augmentation transforms\n",
    "cutmix = v2.CutMix(num_classes=1000, alpha=0.2)\n",
    "mixup = v2.MixUp(num_classes=1000, alpha=0.2)\n",
    "cutmix_or_mixup = v2.RandomChoice([cutmix, mixup])\n",
    "\n",
    "def extract_loop(\n",
    "    model, \n",
    "    teacher, \n",
    "    poi_loader, \n",
    "    loader, \n",
    "    opt, \n",
    "    lr_scheduler, \n",
    "    epoch, \n",
    "    temperature=1.0, \n",
    "    max_epoch=100, \n",
    "    mode='train', \n",
    "    device='cuda'\n",
    "):\n",
    "    \"\"\"\n",
    "    Function to train or evaluate a model using knowledge distillation and augmentation strategies.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model to train or evaluate.\n",
    "        teacher: Pretrained teacher model for distillation.\n",
    "        poi_loader: Poisoned data loader (if applicable).\n",
    "        loader: Data loader for the current dataset.\n",
    "        opt: Optimizer for the model.\n",
    "        lr_scheduler: Learning rate scheduler.\n",
    "        epoch: Current epoch.\n",
    "        temperature: Temperature for knowledge distillation.\n",
    "        max_epoch: Total number of epochs.\n",
    "        mode: 'train' for training, otherwise for evaluation.\n",
    "        device: Device to perform computations ('cuda' or 'cpu').\n",
    "    \"\"\"\n",
    "    T = temperature\n",
    "    \n",
    "    if mode != 'train':  # Evaluation mode\n",
    "        model.eval()\n",
    "        test_num = len(loader.dataset)\n",
    "        acc = 0.0\n",
    "        for test_data in loader:\n",
    "            test_images, test_labels = test_data\n",
    "            test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
    "            outputs = model(test_images)\n",
    "            predict_y = torch.argmax(outputs, dim=1)\n",
    "            acc += torch.eq(predict_y, test_labels).sum().item()\n",
    "\n",
    "        test_accurate = acc / test_num\n",
    "        print(f'Test Accuracy: {test_accurate:.4f}')\n",
    "        return test_accurate  # Return accuracy for logging or monitoring\n",
    "\n",
    "    # Training or Distillation Loop\n",
    "    for batch_idx, batch in enumerate(loader):\n",
    "        images, labels = batch[0].to(device), batch[1].long().to(device)\n",
    "\n",
    "        if mode == 'train':\n",
    "            model.train()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        # Apply random data augmentation (CutMix or MixUp)\n",
    "        if random.randint(1, 5) <= 1:\n",
    "            images, labels = cutmix_or_mixup(images, labels)\n",
    "\n",
    "        # Generate teacher predictions\n",
    "        teacher_preds = teacher(images)\n",
    "\n",
    "        # Randomly decide between normal and adversarial examples\n",
    "        if random.randint(1, 20) > 1:\n",
    "            preds = model(images)  # Normal forward pass\n",
    "        else:\n",
    "            # Add perturbations or apply corruptions\n",
    "            if random.randint(1, 10) > 1:\n",
    "                random_perturbation = perturbations[random.randint(0, len(perturbations) - 1)].to(device)\n",
    "                preds = model(images + random_perturbation)\n",
    "            else:\n",
    "                corrupted_images = images.clone()\n",
    "                for corruption in best_corruptions:\n",
    "                    corrupted_images = corruption(corrupted_images, labels, model, magnitude=1, device=device)[0]\n",
    "                preds = model(torch.clamp(corrupted_images, 0, 1))\n",
    "\n",
    "        # Compute knowledge distillation loss\n",
    "        extract_loss = (\n",
    "            T ** 2 * F.kl_div(\n",
    "                F.log_softmax(preds / T, dim=-1), \n",
    "                F.softmax(teacher_preds / T, dim=-1), \n",
    "                reduction='batchmean'\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Backpropagation and optimization step\n",
    "        if mode == 'train':\n",
    "            extract_loss.backward()\n",
    "            opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction(teacher, model, epochs, poi_loader, train_loader, test_loader, opt, lr_scheduler, device):\n",
    "\n",
    "    teacher.eval()\n",
    "    test_backdoor_attack(teacher, backdoor_testloader, device, lambda x: add_trigger(x, location=(24, 24), size=(3, 3)), target_label=target_label)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('epoch:', epoch)\n",
    "        model.train()\n",
    "        extract_loop(model, teacher, poi_loader, train_loader,\n",
    "                opt, lr_scheduler, epoch, max_epoch=epochs, mode='train', device=device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            extract_loop(model, teacher, poi_loader, test_loader,\n",
    "                opt, lr_scheduler, epoch, max_epoch=epochs, mode='val', device=device)\n",
    "            test_backdoor_attack(model, backdoor_testloader, device, lambda x: add_trigger(x, location=(24, 24), size=(3, 3)), target_label=target_label)\n",
    "        \n",
    "        lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model prepared.\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "\n",
    "teacher = torch.load('../models/badnets/resnet18_50epochs.pth').to(device)\n",
    "from torchvision.models.resnet import resnet18, ResNet18_Weights\n",
    "student = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "student.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "student.maxpool = nn.Identity()\n",
    "student.fc = nn.Linear(512,10)\n",
    "student.to(device)\n",
    "print('model prepared.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(student.parameters(), lr=lr, weight_decay=0.0, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=1e-4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction(teacher=teacher, model=student, epochs=50, poi_loader=None, train_loader=trainloader, test_loader=testloader, opt=optimizer, lr_scheduler=scheduler, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student, '../models/badnets/student.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
